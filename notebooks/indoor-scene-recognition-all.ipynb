{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T13:53:12.230240Z",
     "start_time": "2024-12-09T13:53:12.214368Z"
    },
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2024-12-10T08:28:42.295727Z",
     "iopub.status.busy": "2024-12-10T08:28:42.295727Z",
     "iopub.status.idle": "2024-12-10T08:28:56.996937Z",
     "shell.execute_reply": "2024-12-10T08:28:56.996937Z",
     "shell.execute_reply.started": "2024-12-10T08:28:42.295727Z"
    },
    "papermill": {
     "duration": 1.555755,
     "end_time": "2021-03-13T20:09:24.996078",
     "exception": false,
     "start_time": "2021-03-13T20:09:23.440323",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1e4239fda90>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import random_split\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "random_seed = 123\n",
    "torch.manual_seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T08:28:56.998411Z",
     "iopub.status.busy": "2024-12-10T08:28:56.998411Z",
     "iopub.status.idle": "2024-12-10T08:28:57.376997Z",
     "shell.execute_reply": "2024-12-10T08:28:57.376997Z",
     "shell.execute_reply.started": "2024-12-10T08:28:56.998411Z"
    },
    "papermill": {
     "duration": 0.054906,
     "end_time": "2021-03-13T20:09:25.207702",
     "exception": false,
     "start_time": "2021-03-13T20:09:25.152796",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['artstudio', 'bathroom', 'bedroom', 'children_room', 'closet', 'computerroom', 'dining_room', 'gameroom', 'kitchen', 'livingroom', 'locker_room', 'meeting_room']\n",
      "length: 12\n"
     ]
    }
   ],
   "source": [
    "data_dir  = '../data/Images'\n",
    "\n",
    "classes = os.listdir(data_dir)\n",
    "print(classes)\n",
    "print(f\"length: {len(classes)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T08:29:12.447911Z",
     "iopub.status.busy": "2024-12-10T08:29:12.447911Z",
     "iopub.status.idle": "2024-12-10T09:04:41.716014Z",
     "shell.execute_reply": "2024-12-10T09:04:41.716014Z",
     "shell.execute_reply.started": "2024-12-10T08:29:12.447911Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "Training Model: resnet152\n",
      "dataset size: 3683\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Caught RuntimeError in pin memory thread for device 0.\nOriginal Traceback (most recent call last):\n  File \"C:\\Users\\DELL\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\utils\\data\\_utils\\pin_memory.py\", line 41, in do_one_step\n    data = pin_memory(data, device)\n           ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\DELL\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\utils\\data\\_utils\\pin_memory.py\", line 98, in pin_memory\n    clone[i] = pin_memory(item, device)\n               ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\DELL\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\utils\\data\\_utils\\pin_memory.py\", line 64, in pin_memory\n    return data.pin_memory(device)\n           ^^^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[3], line 146\u001B[0m\n\u001B[0;32m    144\u001B[0m model \u001B[38;5;241m=\u001B[39m ConvClassifier(model_name\u001B[38;5;241m=\u001B[39mmodel_name, dataset\u001B[38;5;241m=\u001B[39mdataset)\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[0;32m    145\u001B[0m optim \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39moptim\u001B[38;5;241m.\u001B[39mAdam(model\u001B[38;5;241m.\u001B[39mparameters(), \u001B[38;5;241m3e-5\u001B[39m)\n\u001B[1;32m--> 146\u001B[0m history, model \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mval_loader\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mval_loader\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    148\u001B[0m plot_accuracies(history, model_name\u001B[38;5;241m=\u001B[39mmodel_name)\n\u001B[0;32m    149\u001B[0m plot_losses(history, model_name\u001B[38;5;241m=\u001B[39mmodel_name)\n",
      "Cell \u001B[1;32mIn[3], line 92\u001B[0m, in \u001B[0;36mtrain_model\u001B[1;34m(model, num_epochs, train_loader, val_loader)\u001B[0m\n\u001B[0;32m     90\u001B[0m \u001B[38;5;66;03m# Validation phase\u001B[39;00m\n\u001B[0;32m     91\u001B[0m model\u001B[38;5;241m.\u001B[39meval()\n\u001B[1;32m---> 92\u001B[0m outputs \u001B[38;5;241m=\u001B[39m \u001B[43m[\u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mvalid_step\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mval_loader\u001B[49m\u001B[43m]\u001B[49m\n\u001B[0;32m     93\u001B[0m result \u001B[38;5;241m=\u001B[39m {\n\u001B[0;32m     94\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mval_loss\u001B[39m\u001B[38;5;124m'\u001B[39m: np\u001B[38;5;241m.\u001B[39mmean([out[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mval_loss\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;28;01mfor\u001B[39;00m out \u001B[38;5;129;01min\u001B[39;00m outputs]), \n\u001B[0;32m     95\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mval_acc\u001B[39m\u001B[38;5;124m'\u001B[39m: np\u001B[38;5;241m.\u001B[39mmean([out[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mval_acc\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;28;01mfor\u001B[39;00m out \u001B[38;5;129;01min\u001B[39;00m outputs]), \n\u001B[0;32m     96\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtrain_loss\u001B[39m\u001B[38;5;124m'\u001B[39m: np\u001B[38;5;241m.\u001B[39mmean(train_losses)\n\u001B[0;32m     97\u001B[0m }\n\u001B[0;32m     98\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m[Epoch \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mepoch\u001B[38;5;241m+\u001B[39m\u001B[38;5;241m1\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m] train_loss: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mresult[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtrain_loss\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.4f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, val_loss: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mresult[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mval_loss\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.4f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, val_acc: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mresult[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mval_acc\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.4f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:701\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    698\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    699\u001B[0m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[0;32m    700\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[1;32m--> 701\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    702\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m    703\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[0;32m    704\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable\n\u001B[0;32m    705\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    706\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called\n\u001B[0;32m    707\u001B[0m ):\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:1465\u001B[0m, in \u001B[0;36m_MultiProcessingDataLoaderIter._next_data\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1463\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1464\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_task_info[idx]\n\u001B[1;32m-> 1465\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_process_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:1491\u001B[0m, in \u001B[0;36m_MultiProcessingDataLoaderIter._process_data\u001B[1;34m(self, data)\u001B[0m\n\u001B[0;32m   1489\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_try_put_index()\n\u001B[0;32m   1490\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(data, ExceptionWrapper):\n\u001B[1;32m-> 1491\u001B[0m     \u001B[43mdata\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreraise\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1492\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m data\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\_utils.py:715\u001B[0m, in \u001B[0;36mExceptionWrapper.reraise\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    711\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[0;32m    712\u001B[0m     \u001B[38;5;66;03m# If the exception takes multiple arguments, don't try to\u001B[39;00m\n\u001B[0;32m    713\u001B[0m     \u001B[38;5;66;03m# instantiate since we don't know how to\u001B[39;00m\n\u001B[0;32m    714\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(msg) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m--> 715\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m exception\n",
      "\u001B[1;31mRuntimeError\u001B[0m: Caught RuntimeError in pin memory thread for device 0.\nOriginal Traceback (most recent call last):\n  File \"C:\\Users\\DELL\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\utils\\data\\_utils\\pin_memory.py\", line 41, in do_one_step\n    data = pin_memory(data, device)\n           ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\DELL\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\utils\\data\\_utils\\pin_memory.py\", line 98, in pin_memory\n    clone[i] = pin_memory(item, device)\n               ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\DELL\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\utils\\data\\_utils\\pin_memory.py\", line 64, in pin_memory\n    return data.pin_memory(device)\n           ^^^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n\n"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "import numpy as np\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torchvision.models import ResNet152_Weights, EfficientNet_B0_Weights, Inception_V3_Weights\n",
    "\n",
    "\n",
    "def dataset_setup(model_name='resnet18'):\n",
    "    if model_name == 'resnet18':\n",
    "        transformations = transforms.Compose([\n",
    "            transforms.Resize((256, 256)),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomRotation(degrees=10),\n",
    "            transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n",
    "            transforms.ToTensor()])\n",
    "    elif model_name == 'efficientnet_b0' or model_name == 'vit_b_16' or model_name == 'resnet152':\n",
    "        transformations = transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomRotation(degrees=10),\n",
    "            transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n",
    "            transforms.ToTensor()])\n",
    "    elif model_name == 'inception_v3':\n",
    "        transformations = transforms.Compose([\n",
    "            transforms.Resize((299, 299)),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomRotation(degrees=10),\n",
    "            transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n",
    "            transforms.ToTensor()])\n",
    "    return transformations\n",
    "\n",
    "def accuracy(outputs, labels):\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    acc = torch.sum(preds == labels).item() / len(preds)\n",
    "    return acc\n",
    "\n",
    "class ConvClassifier(nn.Module):\n",
    "    def __init__(self, model_name='resnet18', dataset=None):\n",
    "        super().__init__()\n",
    "        self.model_name = model_name\n",
    "        if self.model_name == 'resnet18':\n",
    "            self.network = torchvision.models.resnet18(pretrained=True)\n",
    "            self.network.fc = nn.Linear(self.network.fc.in_features, len(dataset.classes))\n",
    "        elif self.model_name == 'resnet152':\n",
    "            self.network = torchvision.models.resnet152(weights=ResNet152_Weights.IMAGENET1K_V1)\n",
    "            self.network.fc = nn.Linear(self.network.fc.in_features, len(dataset.classes))\n",
    "        elif self.model_name == 'efficientnet_b0':\n",
    "            self.network = torchvision.models.efficientnet_b0(weights=EfficientNet_B0_Weights.IMAGENET1K_V1)\n",
    "            self.network.classifier[1] = nn.Linear(self.network.classifier[1].in_features, len(dataset.classes))\n",
    "        elif self.model_name == 'vit_b_16':\n",
    "            self.network = torchvision.models.vit_b_16(pretrained=True)\n",
    "            self.network.heads = nn.Linear(self.network.heads.head.in_features, len(dataset.classes))\n",
    "        elif self.model_name == 'inception_v3':\n",
    "            self.network = torchvision.models.inception_v3(weights=Inception_V3_Weights.IMAGENET1K_V1)\n",
    "            self.network.fc = nn.Linear(self.network.fc.in_features, len(dataset.classes))\n",
    "\n",
    "    def forward(self, xb):\n",
    "        return self.network(xb)\n",
    "    \n",
    "    def training_step(self, batch):\n",
    "        images, labels = batch[0].to(device), batch[1].to(device)\n",
    "        out = self(images)\n",
    "        loss = F.cross_entropy(out, labels)\n",
    "        return loss\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def valid_step(self, batch):\n",
    "        images, labels = batch[0].to(device), batch[1].to(device) \n",
    "        out = self(images)                    # Generate predictions\n",
    "        loss = F.cross_entropy(out, labels)   # Calculate loss\n",
    "        acc = accuracy(out, labels)           # Calculate accuracy\n",
    "        return {'val_loss': loss.item(), 'val_acc': acc}\n",
    "\n",
    "\n",
    "def train_model(model, num_epochs = 10, train_loader=None, val_loader=None):\n",
    "    history = []\n",
    "    for epoch in range(num_epochs):  # Training Phase\n",
    "        model.train()\n",
    "        train_losses = []\n",
    "        for batch in train_loader:\n",
    "            loss = model.training_step(batch)\n",
    "            optim.zero_grad()\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "\n",
    "            train_losses.append(loss.item())\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        outputs = [model.valid_step(batch) for batch in val_loader]\n",
    "        result = {\n",
    "            'val_loss': np.mean([out['val_loss'] for out in outputs]), \n",
    "            'val_acc': np.mean([out['val_acc'] for out in outputs]), \n",
    "            'train_loss': np.mean(train_losses)\n",
    "        }\n",
    "        print(f\"[Epoch {epoch+1}] train_loss: {result['train_loss']:.4f}, val_loss: {result['val_loss']:.4f}, val_acc: {result['val_acc']:.4f}\")\n",
    "        history.append(result)\n",
    "\n",
    "    return history, model\n",
    "\n",
    "def save_model(model_name='resnet18', model=None):\n",
    "    torch.save(model.state_dict(), f\"{model_name}.pth\")\n",
    "    model.load_state_dict(torch.load(f\"{model_name}.pth\"))\n",
    "\n",
    "def plot_accuracies(history, model_name='resnet18'):\n",
    "    accuracies = [x['val_acc'] for x in history]\n",
    "    plt.plot(accuracies, '-')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.title(model_name)\n",
    "\n",
    "\n",
    "def plot_losses(history, model_name='resnet18'):\n",
    "    train_losses = [x.get('train_loss') for x in history]\n",
    "    val_losses = [x['val_loss'] for x in history]\n",
    "    plt.plot(train_losses, '-b')\n",
    "    plt.plot(val_losses, '-r')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('loss')\n",
    "    plt.legend(['Train loss', 'Val loss'])\n",
    "    plt.title(model_name);\n",
    "\n",
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "# models_to_train = ['resnet152', 'efficientnet_b0', 'inception_v3']\n",
    "models_to_train = ['resnet152']\n",
    "for model_name in models_to_train:\n",
    "    print(f\"Training Model: {model_name}\")\n",
    "    transformations = dataset_setup(model_name=model_name)\n",
    "    dataset = ImageFolder(data_dir, transform = transformations)\n",
    "    print(f\"dataset size: {len(dataset)}\")\n",
    "\n",
    "    batch_size = 64\n",
    "    train_ds, val_ds, test_ds = random_split(dataset, [2800, 500, 383])\n",
    "    train_loader = DataLoader(train_ds, batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "    val_loader = DataLoader(val_ds, batch_size*2, num_workers=4, pin_memory=True)\n",
    "\n",
    "    model = ConvClassifier(model_name=model_name, dataset=dataset).to(device)\n",
    "    optim = torch.optim.Adam(model.parameters(), 3e-5)\n",
    "    history, model = train_model(model=model, train_loader=train_loader, val_loader=val_loader)\n",
    "\n",
    "    plot_accuracies(history, model_name=model_name)\n",
    "    plot_losses(history, model_name=model_name)\n",
    "\n",
    "    save_model(model_name=model_name, model=model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.050467,
     "end_time": "2021-03-13T20:30:45.804691",
     "exception": false,
     "start_time": "2021-03-13T20:30:45.754224",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Visualizing Predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-09T02:06:19.052900Z",
     "iopub.status.busy": "2024-12-09T02:06:19.052900Z",
     "iopub.status.idle": "2024-12-09T02:06:19.073872Z",
     "shell.execute_reply": "2024-12-09T02:06:19.072865Z",
     "shell.execute_reply.started": "2024-12-09T02:06:19.052900Z"
    },
    "papermill": {
     "duration": 0.0585,
     "end_time": "2021-03-13T20:30:45.913783",
     "exception": false,
     "start_time": "2021-03-13T20:30:45.855283",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict_image(img, model):\n",
    "    xb = img.unsqueeze(0).to(device)         # Convert to a batch of 1\n",
    "    yb = model(xb)                           # Get predictions from model\n",
    "    prob, preds  = torch.max(yb, dim=1)      # Pick index with highest probability\n",
    "    return dataset.classes[preds[0].item()]  # Retrieve the class label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.049923,
     "end_time": "2021-03-13T20:30:46.014521",
     "exception": false,
     "start_time": "2021-03-13T20:30:45.964598",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Let us see the model's predictions on the test dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-09T02:06:23.250946Z",
     "iopub.status.busy": "2024-12-09T02:06:23.249940Z",
     "iopub.status.idle": "2024-12-09T02:06:24.209447Z",
     "shell.execute_reply": "2024-12-09T02:06:24.209447Z",
     "shell.execute_reply.started": "2024-12-09T02:06:23.250946Z"
    },
    "papermill": {
     "duration": 0.235874,
     "end_time": "2021-03-13T20:30:46.300543",
     "exception": false,
     "start_time": "2021-03-13T20:30:46.064669",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "img, label = test_ds[17]\n",
    "plt.imshow(img.permute(1, 2, 0))\n",
    "print('Label:', dataset.classes[label], ', Predicted:', predict_image(img, model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-09T02:06:28.939431Z",
     "iopub.status.busy": "2024-12-09T02:06:28.939431Z",
     "iopub.status.idle": "2024-12-09T02:06:29.543469Z",
     "shell.execute_reply": "2024-12-09T02:06:29.543469Z",
     "shell.execute_reply.started": "2024-12-09T02:06:28.939431Z"
    },
    "papermill": {
     "duration": 0.229268,
     "end_time": "2021-03-13T20:30:46.583663",
     "exception": false,
     "start_time": "2021-03-13T20:30:46.354395",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "img, label = test_ds[23]\n",
    "plt.imshow(img.permute(1, 2, 0))\n",
    "print('Label:', dataset.classes[label], ', Predicted:', predict_image(img, model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-09T02:06:33.063453Z",
     "iopub.status.busy": "2024-12-09T02:06:33.063453Z",
     "iopub.status.idle": "2024-12-09T02:06:33.679611Z",
     "shell.execute_reply": "2024-12-09T02:06:33.679611Z",
     "shell.execute_reply.started": "2024-12-09T02:06:33.063453Z"
    },
    "papermill": {
     "duration": 0.23095,
     "end_time": "2021-03-13T20:30:46.87179",
     "exception": false,
     "start_time": "2021-03-13T20:30:46.64084",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "img, label = test_ds[51]\n",
    "plt.imshow(img.permute(1, 2, 0))\n",
    "print('Label:', dataset.classes[label], ', Predicted:', predict_image(img, model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.060013,
     "end_time": "2021-03-13T20:30:46.991904",
     "exception": false,
     "start_time": "2021-03-13T20:30:46.931891",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Predicting External Images:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.060485,
     "end_time": "2021-03-13T20:30:47.112391",
     "exception": false,
     "start_time": "2021-03-13T20:30:47.051906",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Let's now test with external images.\n",
    "\n",
    "I'll use `urllib` for downloading external images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-09T02:06:38.539898Z",
     "iopub.status.busy": "2024-12-09T02:06:38.538893Z",
     "iopub.status.idle": "2024-12-09T02:06:39.485304Z",
     "shell.execute_reply": "2024-12-09T02:06:39.483995Z",
     "shell.execute_reply.started": "2024-12-09T02:06:38.539898Z"
    },
    "papermill": {
     "duration": 4.56965,
     "end_time": "2021-03-13T20:30:51.741717",
     "exception": false,
     "start_time": "2021-03-13T20:30:47.172067",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "# urllib.request.urlretrieve(\"https://images.squarespace-cdn.com/content/v1/5a7497e29f8dcee376b70f7e/1591630503059-FBBWAYXPWYOK9BTIBMZY/ke17ZwdGBToddI8pDm48kA_SSaoz4elkj-HsZd8gX3Z7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1UWPwZyNcweDIvdeL5kotwkIXjs9g0WibSO_cU-Ijy4Pwg6poS-6WGGnXqDacZer4yQ/74586587_10157705983079085_1307946016988725248_o+%281%29.jpg?format=2500w\", \"bar.jpg\")\n",
    "# urllib.request.urlretrieve(\"https://www.bocadolobo.com/en/inspiration-and-ideas/wp-content/uploads/2018/03/Discover-the-Ultimate-Master-Bedroom-Styles-and-Inspirations-6_1.jpg\", \"bedroom.jpg\")    \n",
    "# urllib.request.urlretrieve(\"https://sika.scene7.com/is/image/sika/glo-elevator-appliances?wid=1280&crop=0%2C80%2C4615%2C3212\", \"elevator.jpg\") \n",
    "urllib.request.urlretrieve(\"https://i.pinimg.com/originals/2b/15/9d/2b159da035e4e3aaa30c03ec8ba7816c.jpg\", \"gameroom.jpg\")\n",
    "# urllib.request.urlretrieve(\"https://i.pinimg.com/originals/a6/d9/d7/a6d9d743da7017a7bcf4a53e46d22f81.jpg\", \"inside_bus.jpg\")\n",
    "# urllib.request.urlretrieve(\"https://s.wsj.net/public/resources/images/ON-CE927_moviet_B1280_20170714200426.jpg\", \"theatre.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.061596,
     "end_time": "2021-03-13T20:30:51.86465",
     "exception": false,
     "start_time": "2021-03-13T20:30:51.803054",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Let us load the model. You can load an external pre-trained model too!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-09T02:06:42.590916Z",
     "iopub.status.busy": "2024-12-09T02:06:42.590916Z",
     "iopub.status.idle": "2024-12-09T02:06:42.594680Z",
     "shell.execute_reply": "2024-12-09T02:06:42.594680Z",
     "shell.execute_reply.started": "2024-12-09T02:06:42.590916Z"
    },
    "papermill": {
     "duration": 0.067839,
     "end_time": "2021-03-13T20:30:51.993865",
     "exception": false,
     "start_time": "2021-03-13T20:30:51.926026",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "loaded_model = model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.061105,
     "end_time": "2021-03-13T20:30:52.116371",
     "exception": false,
     "start_time": "2021-03-13T20:30:52.055266",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This function takes the image's name and prints the predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-09T02:06:44.999639Z",
     "iopub.status.busy": "2024-12-09T02:06:44.999639Z",
     "iopub.status.idle": "2024-12-09T02:06:45.011370Z",
     "shell.execute_reply": "2024-12-09T02:06:45.011370Z",
     "shell.execute_reply.started": "2024-12-09T02:06:44.999639Z"
    },
    "papermill": {
     "duration": 0.069081,
     "end_time": "2021-03-13T20:30:52.245972",
     "exception": false,
     "start_time": "2021-03-13T20:30:52.176891",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "\n",
    "def predict_external_image(image_name):\n",
    "    image = Image.open(Path('./' + image_name))\n",
    "\n",
    "    example_image = transformations(image)\n",
    "    plt.imshow(example_image.permute(1, 2, 0))\n",
    "    print(\"The image resembles\", predict_image(example_image, loaded_model) + \".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-09T02:06:46.729709Z",
     "iopub.status.busy": "2024-12-09T02:06:46.728666Z",
     "iopub.status.idle": "2024-12-09T02:06:48.545675Z",
     "shell.execute_reply": "2024-12-09T02:06:48.545675Z",
     "shell.execute_reply.started": "2024-12-09T02:06:46.729709Z"
    },
    "papermill": {
     "duration": 0.272528,
     "end_time": "2021-03-13T20:30:52.579185",
     "exception": false,
     "start_time": "2021-03-13T20:30:52.306657",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "predict_external_image('bar.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-09T02:07:11.371110Z",
     "iopub.status.busy": "2024-12-09T02:07:11.370111Z",
     "iopub.status.idle": "2024-12-09T02:07:11.413971Z",
     "shell.execute_reply": "2024-12-09T02:07:11.412257Z",
     "shell.execute_reply.started": "2024-12-09T02:07:11.371110Z"
    },
    "papermill": {
     "duration": 0.247474,
     "end_time": "2021-03-13T20:30:52.891154",
     "exception": false,
     "start_time": "2021-03-13T20:30:52.64368",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "predict_external_image('bedroom.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-09T02:07:12.183462Z",
     "iopub.status.busy": "2024-12-09T02:07:12.183462Z",
     "iopub.status.idle": "2024-12-09T02:07:12.224964Z",
     "shell.execute_reply": "2024-12-09T02:07:12.223957Z",
     "shell.execute_reply.started": "2024-12-09T02:07:12.183462Z"
    },
    "papermill": {
     "duration": 0.250468,
     "end_time": "2021-03-13T20:30:53.209119",
     "exception": false,
     "start_time": "2021-03-13T20:30:52.958651",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "predict_external_image('elevator.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-09T02:07:12.649334Z",
     "iopub.status.busy": "2024-12-09T02:07:12.648326Z",
     "iopub.status.idle": "2024-12-09T02:07:13.472353Z",
     "shell.execute_reply": "2024-12-09T02:07:13.472353Z",
     "shell.execute_reply.started": "2024-12-09T02:07:12.649334Z"
    },
    "papermill": {
     "duration": 0.261299,
     "end_time": "2021-03-13T20:30:53.540093",
     "exception": false,
     "start_time": "2021-03-13T20:30:53.278794",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "predict_external_image('gameroom.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-09T02:07:13.472353Z",
     "iopub.status.busy": "2024-12-09T02:07:13.472353Z",
     "iopub.status.idle": "2024-12-09T02:07:13.518752Z",
     "shell.execute_reply": "2024-12-09T02:07:13.518752Z",
     "shell.execute_reply.started": "2024-12-09T02:07:13.472353Z"
    },
    "papermill": {
     "duration": 0.258008,
     "end_time": "2021-03-13T20:30:53.878861",
     "exception": false,
     "start_time": "2021-03-13T20:30:53.620853",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "predict_external_image('inside_bus.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-09T02:06:54.770811Z",
     "iopub.status.busy": "2024-12-09T02:06:54.769815Z",
     "iopub.status.idle": "2024-12-09T02:06:54.870988Z",
     "shell.execute_reply": "2024-12-09T02:06:54.869982Z",
     "shell.execute_reply.started": "2024-12-09T02:06:54.770811Z"
    },
    "papermill": {
     "duration": 0.26608,
     "end_time": "2021-03-13T20:30:54.259787",
     "exception": false,
     "start_time": "2021-03-13T20:30:53.993707",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "predict_external_image('theatre.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.078194,
     "end_time": "2021-03-13T20:30:54.417574",
     "exception": false,
     "start_time": "2021-03-13T20:30:54.33938",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Conclusion:\n",
    "\n",
    "Our model is able to classify indoor with **76% accuracy (max)**!\n",
    "\n",
    "It's great to see the model's predictions on the test set. It works pretty good on external images too!\n",
    "\n",
    "You can try experimenting with more images and see the results!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.091781,
     "end_time": "2021-03-13T20:30:54.588889",
     "exception": false,
     "start_time": "2021-03-13T20:30:54.497108",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### If you liked the kernel, don't forget to show some appreciation :)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
