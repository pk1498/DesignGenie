{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "GmFzROAFsOHE"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.models.detection import FasterRCNN\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "from torchvision.datasets import CocoDetection\n",
        "from torchvision.transforms import functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "gy8Du4K_sbIl"
      },
      "outputs": [],
      "source": [
        "# Define transformations\n",
        "class CocoTransform:\n",
        "    def __call__(self, image, target):\n",
        "        image = F.to_tensor(image)  # Convert PIL image to tensor\n",
        "        return image, target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sTEiAknXRs4h",
        "outputId": "8eaeb35a-21dc-4046-fbe4-fd2c07bd4f06"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " \u001b[0m\u001b[01;32mFaster_RCNN.ipynb\u001b[0m*    \u001b[01;32m'fasterrcnn_resnet50_epoch_(epoch + 1).pth'\u001b[0m*   \u001b[01;34mvalid\u001b[0m/\n",
            " \u001b[01;32mREADME.dataset.txt\u001b[0m*    \u001b[01;34mtest\u001b[0m/\n",
            " \u001b[01;32mREADME.roboflow.txt\u001b[0m*   \u001b[01;34mtrain\u001b[0m/\n"
          ]
        }
      ],
      "source": [
        "%ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "gsOtcLjtssVH",
        "outputId": "ca6e17c7-b7e4-45c6-a06d-4ecce5259afe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n"
          ]
        }
      ],
      "source": [
        "# Dataset class\n",
        "def get_coco_dataset(img_dir, ann_file):\n",
        "    return CocoDetection(\n",
        "        root=img_dir,\n",
        "        annFile=ann_file,\n",
        "        transforms=CocoTransform()\n",
        "    )\n",
        "\n",
        "# Load datasets\n",
        "train_dataset = get_coco_dataset(\n",
        "    img_dir=\"train\",\n",
        "    ann_file=\"train/annotations/train_annotations.json\"\n",
        ")\n",
        "\n",
        "val_dataset = get_coco_dataset(\n",
        "    img_dir=\"valid\",\n",
        "    ann_file=\"valid/annotations/valid_annotations.json\"\n",
        ")\n",
        "\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, collate_fn=lambda batch: tuple(zip(*batch)))\n",
        "val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False, collate_fn=lambda batch: tuple(zip(*batch)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "6PE4tRUfssO1"
      },
      "outputs": [],
      "source": [
        "# Load Faster R-CNN with ResNet-50 backbone\n",
        "def get_model(num_classes):\n",
        "    # Load pre-trained Faster R-CNN\n",
        "    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
        "\n",
        "    # Get the number of input features for the classifier\n",
        "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "\n",
        "    # Replace the pre-trained head with a new one\n",
        "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "E554qsjstWIm"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=FasterRCNN_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=FasterRCNN_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ],
      "source": [
        "# Initialize the model\n",
        "num_classes = 13  # Background + chair, human, table\n",
        "model = get_model(num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "xkSMhU6CueNg"
      },
      "outputs": [],
      "source": [
        "#Move model to GPU if available\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "model.to(device)\n",
        "\n",
        "#Define optimizer and Learning rate scheduler\n",
        "params = [p for p in model.parameters() if p.requires_grad]\n",
        "optimizer = torch.optim.SGD(params, lr=0.0005, momentum=0.9, weight_decay=0.0005)\n",
        "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "1X8_9Otnu7wZ"
      },
      "outputs": [],
      "source": [
        "def train_one_epoch(model, optimizer, data_loader, device, epoch):\n",
        "  model.train()\n",
        "\n",
        "  for images, targets in data_loader:\n",
        "    #Move images to the device\n",
        "    images = [img.to (device) for img in images]\n",
        "\n",
        "    # Validate and process targets\n",
        "    processed_targets = []\n",
        "    valid_images = []\n",
        "    for i, target in enumerate(targets):\n",
        "      boxes = []\n",
        "      labels = []\n",
        "      for obj in target:\n",
        "        #Extract bbox\n",
        "        bbox = obj[\"bbox\"] # Format: (x, y, width, height]\n",
        "        x, y, w, h = bbox\n",
        "\n",
        "        #Ensure the width and height are positive\n",
        "        if w > 0 and h> 0:\n",
        "          boxes.append([x, y, x + w, y + h]) # Convert to [x_min, y_min, x_max, y_max]\n",
        "          labels.append(obj[\"category_id\"])\n",
        "\n",
        "      #Only process if there are valid boxes\n",
        "      if boxes:\n",
        "        processed_target= {\n",
        "          \"boxes\": torch.tensor (boxes, dtype=torch.float32).to (device),\n",
        "          \"labels\": torch.tensor(labels, dtype=torch.int64).to(device),\n",
        "        }\n",
        "        processed_targets.append(processed_target)\n",
        "        valid_images.append(images[i]) # Add only valid images\n",
        "\n",
        "    #Skip iteration if no valid targets\n",
        "    if not processed_targets:\n",
        "      continue\n",
        "\n",
        "    #Ensure images and targets are aligned\n",
        "    images = valid_images\n",
        "\n",
        "    #Forward pass\n",
        "    loss_dict = model(images, processed_targets)\n",
        "    losses = sum(loss for loss in loss_dict.values())\n",
        "\n",
        "    #Backpropagation\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    losses.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "  print(f\"Epoch [{epoch}] Loss: {losses.item():.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "0lZSoPtKxeVk"
      },
      "outputs": [],
      "source": [
        "#Training loop\n",
        "num_epochs = 2\n",
        "for epoch in range(num_epochs):\n",
        "  train_one_epoch (model, optimizer, train_loader, device, epoch)\n",
        "  lr_scheduler.step()\n",
        "\n",
        "  #Save the model's state dictionary after every epoch\n",
        "  model_path = f\"fasterrcnn_resnet50_epoch_{epoch + 1}.pth\"\n",
        "  torch.save(model.state_dict(), model_path)\n",
        "  print(f\"Model saved: (model_path)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
